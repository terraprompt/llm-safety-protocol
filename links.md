# Links from OpenAI Harmony Protocol and AI Safety Report

## OpenAI Harmony Protocol Resources
- [OpenAI Harmony Response Format | OpenAI Cookbook](https://cookbook.openai.com/articles/openai-harmony)
- [openai-harmony · PyPI](https://pypi.org/project/openai-harmony/)
- [GitHub - openai/harmony: Renderer for the harmony response format to be used with gpt-oss](https://github.com/openai/harmony)
- [GitHub - mbrukman/openai-harmony: Renderer for the harmony response format to be used with gpt-oss](https://github.com/mbrukman/openai-harmony)
- [openai/gpt-oss-120b · Hugging Face](https://huggingface.co/openai/gpt-oss-120b)
- [How to handle the raw chain of thought in gpt-oss | OpenAI Cookbook](https://cookbook.openai.com/articles/gpt-oss/handle-raw-cot)
- [What is GPT OSS Harmony Response Format? | by Cobus Greyling | Aug, 2025 | Medium](https://cobusgreyling.medium.com/what-is-gpt-oss-harmony-response-format-a29f266d6672)

## Anthropic's Constitutional AI
- [Constitutional AI: Harmlessness from AI Feedback](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback)
- [Constitutional AI - PRIMO.ai](https://primo.ai/index.php?title=Constitutional_AI)
- [What is Constitutional AI (CAI)? - Zilliz Learn](https://zilliz.com/learn/constitutional-ai-harmlessness-from-ai-feedback)
- [Claude's Constitution \ Anthropic](https://www.anthropic.com/news/claudes-constitution)
- [Understanding Constitutional AI. Constitutional AI provides a… | by Jonathan Davis | Medium](https://medium.com/@jonnyndavis/understanding-constitutional-ai-dd9d783ef712)
- [Constitutional Classifiers: Defending against universal jailbreaks \ Anthropic](https://www.anthropic.com/news/constitutional-classifiers)

## Google's AI Safety Framework
- [Google's Secure AI Framework - Google Safety Center](https://safety.google/cybersecurity-advancements/saif/)
- [Introducing the Frontier Safety Framework](https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/)

## Meta's Safety Approaches
- [Safeguarding Your RAG Pipelines: A Step-by-Step Guide to Implementing Llama Guard with LlamaIndex | Towards Data Science](https://towardsdatascience.com/safeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756-2/)
- [The Dispatch Report: GitHub Repo Analysis: meta-llama/PurpleLlama](https://thedispatch.ai/reports/792/)

## Open Source AI Safety Implementation
- [Constitutional AI with Open LLMs](https://huggingface.co/blog/constitutional_ai)
- [GitHub - OpenRLHF/OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework](https://github.com/OpenRLHF/OpenRLHF)
- [[2405.11143] OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework](https://arxiv.org/abs/2405.11143)
- [GitHub - ottosulin/awesome-ai-security: A collection of awesome resources related AI security](https://github.com/ottosulin/awesome-ai-security)

## Industry Analysis and Tools
- [AI research takes a backseat to profits as Silicon Valley prioritizes products over safety, experts say](https://www.cnbc.com/2025/05/14/meta-google-openai-artificial-intelligence-safety.html)
- [Mistral AI Models Fail Key Safety Tests, Report Finds](https://www.bankinfosecurity.com/mistral-ai-models-fail-key-safety-tests-report-finds-a-28358)
- [GPU Memory Essentials for AI Performance | NVIDIA Technical Blog](https://developer.nvidia.com/blog/gpu-memory-essentials-for-ai-performance/)
- [7 AI Security Tools to Prepare You for Every Attack Phase | Wiz](https://www.wiz.io/academy/ai-security-tools)
